{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.decomposition import NMF,LatentDirichletAllocation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "us = pickle.load(open(\"wikivoyage_text_US.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(us,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns=({ 'index' : 'Name'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AbercrombiePAGE</td>\n",
       "      <td>{{pagebanner|Abercrombie WikiVoyage Banner ND....</td>\n",
       "      <td>page</td>\n",
       "      <td>//tools.wmflabs.org/wikivoyage/w/poimap2.php?l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aberdeen (Maryland)PAGE</td>\n",
       "      <td>{{pagebanner|Aberdeen MD WikiVoyage Banner.jpg...</td>\n",
       "      <td>page</td>\n",
       "      <td>//tools.wmflabs.org/wikivoyage/w/poimap2.php?l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aberdeen (South Dakota)PAGE</td>\n",
       "      <td>{{pagebanner|Pagebanner default.jpg|pgname=Abe...</td>\n",
       "      <td>page</td>\n",
       "      <td>//tools.wmflabs.org/wikivoyage/w/poimap2.php?l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aberdeen (Washington)PAGE</td>\n",
       "      <td>{{Pagebanner|pgname=Aberdeen |Wikivoyage page ...</td>\n",
       "      <td>page</td>\n",
       "      <td>//tools.wmflabs.org/wikivoyage/w/poimap2.php?l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AbernathyPAGE</td>\n",
       "      <td>{{pagebanner|Abernathy Texas Wikivoyage Banner...</td>\n",
       "      <td>page</td>\n",
       "      <td>//tools.wmflabs.org/wikivoyage/w/poimap2.php?l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name  \\\n",
       "0              AbercrombiePAGE   \n",
       "1      Aberdeen (Maryland)PAGE   \n",
       "2  Aberdeen (South Dakota)PAGE   \n",
       "3    Aberdeen (Washington)PAGE   \n",
       "4                AbernathyPAGE   \n",
       "\n",
       "                                                text  type  \\\n",
       "0  {{pagebanner|Abercrombie WikiVoyage Banner ND....  page   \n",
       "1  {{pagebanner|Aberdeen MD WikiVoyage Banner.jpg...  page   \n",
       "2  {{pagebanner|Pagebanner default.jpg|pgname=Abe...  page   \n",
       "3  {{Pagebanner|pgname=Aberdeen |Wikivoyage page ...  page   \n",
       "4  {{pagebanner|Abernathy Texas Wikivoyage Banner...  page   \n",
       "\n",
       "                                                 loc  \n",
       "0  //tools.wmflabs.org/wikivoyage/w/poimap2.php?l...  \n",
       "1  //tools.wmflabs.org/wikivoyage/w/poimap2.php?l...  \n",
       "2  //tools.wmflabs.org/wikivoyage/w/poimap2.php?l...  \n",
       "3  //tools.wmflabs.org/wikivoyage/w/poimap2.php?l...  \n",
       "4  //tools.wmflabs.org/wikivoyage/w/poimap2.php?l...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unwiki(wiki):\n",
    "        \"\"\"\n",
    "       Remove wiki markup from the text.\n",
    "       \"\"\"\n",
    "        wiki = re.sub(r'(?i)\\{\\{IPA(\\-[^\\|\\{\\}]+)*?\\|([^\\|\\{\\}]+)(\\|[^\\{\\}]+)*?\\}\\}', lambda m: m.group(2), wiki)\n",
    "        wiki = re.sub(r'(?i)\\{\\{Lang(\\-[^\\|\\{\\}]+)*?\\|([^\\|\\{\\}]+)(\\|[^\\{\\}]+)*?\\}\\}', lambda m: m.group(2), wiki)\n",
    "        wiki = re.sub(r'\\{\\{[^\\{\\}]+\\}\\}', '', wiki)\n",
    "        wiki = re.sub(r'(?m)\\{\\{[^\\{\\}]+\\}\\}', '', wiki)\n",
    "        wiki = re.sub(r'(?m)\\{\\|[^\\{\\}]*?\\|\\}', '', wiki)\n",
    "        wiki = re.sub(r'(?i)\\[\\[Category:[^\\[\\]]*?\\]\\]', '', wiki)\n",
    "        wiki = re.sub(r'(?i)\\[\\[Image:[^\\[\\]]*?\\]\\]', '', wiki)\n",
    "        wiki = re.sub(r'(?i)\\[\\[File:[^\\[\\]]*?\\]\\]', '', wiki)\n",
    "        wiki = re.sub(r'\\[\\[[^\\[\\]]*?\\|([^\\[\\]]*?)\\]\\]', lambda m: m.group(1), wiki)\n",
    "        wiki = re.sub(r'\\[\\[([^\\[\\]]+?)\\]\\]', lambda m: m.group(1), wiki)\n",
    "        wiki = re.sub(r'\\[\\[([^\\[\\]]+?)\\]\\]', '', wiki)\n",
    "        wiki = re.sub(r'(?i)File:[^\\[\\]]*?', '', wiki)\n",
    "        wiki = re.sub(r'\\[[^\\[\\]]*? ([^\\[\\]]*?)\\]', lambda m: m.group(1), wiki)\n",
    "        wiki = re.sub(r\"''+\", '', wiki)\n",
    "        wiki = re.sub(r'(?m)^\\*$', '', wiki)\n",
    "       \n",
    "        return wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unhtml(html):\n",
    "        \"\"\"\n",
    "       Remove HTML from the text.\n",
    "       \"\"\"\n",
    "        html = re.sub(r'(?i)&nbsp;', ' ', html)\n",
    "        html = re.sub(r'(?i)<br[ \\\\]*?>', '\\n', html)\n",
    "        html = re.sub(r'(?m)<!--.*?--\\s*>', '', html)\n",
    "        html = re.sub(r'(?i)<ref[^>]*>[^>]*<\\/ ?ref>', '', html)\n",
    "        html = re.sub(r'(?m)<.*?>', '', html)\n",
    "        html = re.sub(r'(?i)&amp;', '&', html)\n",
    "       \n",
    "        return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return unhtml(unwiki(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words=\"english\", max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_features = vect.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=20, random_state=1, alpha=0, l1_ratio=0)\n",
    "W = nmf.fit_transform(x_features)\n",
    "H = nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vector_features = vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print \"Topic #%d:\" % topic_idx\n",
    "        print \" \".join(sorted([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]],key=lambda x: len(x),reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_top_words(nmf, vector_features, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for topic in range(W.shape[1]):\n",
    "    #max_t = np.argmax(W[:,topic])\n",
    "    print \"TOPIC: #\",topic\n",
    "    #print features[max_t][0:150]\n",
    "    \n",
    "    for t in range(10):\n",
    "        n = int(-1-t)\n",
    "        max_2t = W[:,topic].argsort()[n]\n",
    "        print df['Name'][max_2t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(df[df['Name']=='Touring prestigious and notable universities in the U.S.PAGE']['loc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pages = df[df['type'] == 'page']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return re.sub('PAGE', '', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "pages['Name'] = pages['Name'].apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(\"//tools.wmflabs.org/wikivoyage/w/poimap2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pages = pages[pages['loc'].str.contains(\"//tools.wmflabs.org/wikivoyage/w/poimap2\")==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "StopWords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "StopPlaces = list(pages['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "StopPlaces = map(lambda x: re.sub(\"\\(|\\)\", '',x), StopPlaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "StopPlaces = map(lambda x: x.lower().split(), StopPlaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "StopPlaces = [item for sublist in StopPlaces for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "StopWords = StopPlaces + StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "StopWords = list(set(StopWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words=StopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = pages['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_features = vect.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=20, random_state=1, alpha=0, l1_ratio=0)\n",
    "W = nmf.fit_transform(x_features)\n",
    "H = nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vector_features = vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_top_words(nmf, vector_features, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for topic in range(W.shape[1]):\n",
    "    #max_t = np.argmax(W[:,topic])\n",
    "    print \"TOPIC: #\",topic\n",
    "    #print features[max_t][0:150]\n",
    "    \n",
    "    for t in range(10):\n",
    "        n = int(-1-t)\n",
    "        max_2t = W[:,topic].argsort()[n]\n",
    "        print list(pages['Name'])[max_2t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "StopWords = StopWords + map(lambda x: x.split(\"/\"), StopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "StopWords = [item for sublist in StopWords for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TFIDFvect = TfidfVectorizer(stop_words=StopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_features = TFIDFvect.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=20, random_state=1, alpha=0, l1_ratio=0)\n",
    "W = nmf.fit_transform(x_features)\n",
    "H = nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vector_features = TFIDFvect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_top_words(nmf, vector_features, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for topic in range(W.shape[1]):\n",
    "    #max_t = np.argmax(W[:,topic])\n",
    "    print \"TOPIC: #\",topic\n",
    "    #print features[max_t][0:150]\n",
    "    \n",
    "    for t in range(10):\n",
    "        n = int(-1-t)\n",
    "        max_2t = W[:,topic].argsort()[n]\n",
    "        print list(pages['Name'])[max_2t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_topics=20, random_state=1)\n",
    "W = lda.fit_transform(x_features)\n",
    "H = lda.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vector_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-f7e3cb856da0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_top_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvector_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'vector_features' is not defined"
     ]
    }
   ],
   "source": [
    "print_top_words(lda,vector_features, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for topic in range(W.shape[1]):\n",
    "    #max_t = np.argmax(W[:,topic])\n",
    "    print \"TOPIC: #\",topic\n",
    "    #print features[max_t][0:150]\n",
    "    \n",
    "    for t in range(10):\n",
    "        n = int(-1-t)\n",
    "        max_2t = W[:,topic].argsort()[n]\n",
    "        print list(pages['Name'])[max_2t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pages[pages['Name'] == 'Buffalo/East Side']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print len(pages['text'].ix[801])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    x = re.sub(r'WikiPedia:([\\s\\S]*)','', x)\n",
    "    x = re.sub(r'Dmoz:([\\s\\S]*)','', x)\n",
    "    x = re.sub(r'\\[([\\s\\S]*)\\]','', x)\n",
    "    x = re.sub(r'[0-9]','', x)\n",
    "    x = re.sub(r'\\=\\=Get in\\=\\=([\\s\\S]*)(?=\\=\\=Get around\\=\\=)','',x)\n",
    "    x = re.sub(r'\\=\\=Get around\\=\\=([\\s\\S]*)(?=\\=\\=See\\=\\=)','',x)\n",
    "    x = re.sub(r'\\=\\=Respect\\=\\=([\\s\\S]*)(?=\\=\\=Go next\\=\\=)','',x)\n",
    "    x = re.sub(r'\\=\\=Stay safe\\=\\=([\\s\\S]*)(?=\\=\\=Go next\\=\\=)','',x)\n",
    "    x = re.sub(r'\\=\\=([\\S ]*)\\=\\=', '', x)\n",
    "    x = re.sub(r'\\=\\=Go next\\=\\=([\\s\\S]*)','', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pages['regex_text'] = pages['text'].apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pages['len'] = map(lambda x: len(x), pages['regex_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pages2 = pages[pages['len']> 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2516"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import LabeledSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, doc_list, labels_list):\n",
    "        self.labels_list = labels_list\n",
    "        self.doc_list = doc_list\n",
    "    def __iter__(self):\n",
    "        for idx, doc in enumerate(self.doc_list):\n",
    "            yield LabeledSentence(words=doc,tags=[self.labels_list[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 2513, 2514, 2515])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([i for i,j in enumerate(list(pages2[\"Name\"])) if \"Airport\" not in j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pages3 = pages2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pages3 = pages3.ix[np.array([i for i,j in enumerate(list(pages2[\"Name\"])) if \"Airport\" not in j])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = list(pages3['regex_text'].apply(lambda x: \"\".join(x.lower().splitlines())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [tokenizer.tokenize(x) for x in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_list = list(pages3['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "it = LabeledLineSentence(features, labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Doc2Vec(size=300, window=10, min_count=5, workers=11,alpha=0.025, min_alpha=0.025) # use fixed learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.build_vocab(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    model.train(it)\n",
    "    model.alpha -= 0.002 # decrease the learning rate\n",
    "    model.min_alpha = model.alpha # fix the learning rate, no deca\n",
    "    model.train(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"doc2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Texas Panhandle', 0.25897830724716187),\n",
       " (u'Lubbock', 0.23987515270709991),\n",
       " (u'Garland (Texas)', 0.23293527960777283),\n",
       " (u'Montgomery', 0.22636441886425018),\n",
       " (u'Baltimore/Downtown', 0.22568699717521667),\n",
       " (u'Irving', 0.21994465589523315),\n",
       " (u'Walt Disney World/Disney Springs', 0.21741271018981934),\n",
       " (u'Hoboken', 0.2170657366514206),\n",
       " (u'South Texas Plains', 0.2145078182220459),\n",
       " (u'Albuquerque', 0.20683950185775757)]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.most_similar(positive=[\"Las Vegas\", \"Texas\"],negative=[\"Nevada\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Doc2Vec' object has no attribute 'syn0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-dad8bf127202>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mu'Aberdeen (Washington)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m   1257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1259\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Doc2Vec' object has no attribute 'syn0'"
     ]
    }
   ],
   "source": [
    "model[u'Aberdeen (Washington)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4787    New York (state)\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages2[pages2['Name'] == \"New York (state)\"]['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TFIDFvect = TfidfVectorizer(stop_words=StopWords,max_features=5000)\n",
    "x_features = TFIDFvect.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=20, random_state=1, alpha=0, l1_ratio=0)\n",
    "W = nmf.fit_transform(x_features)\n",
    "H = nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "although however looking usually people around places locals though really pretty hotels always visit night local check would quite right often small good find also like want even much time take best food many make well bars nice sure less look away get one see lot try re go ll\n",
      "Topic #1:\n",
      "neighborhoods neighborhood residential commercial industrial buildings streetcar broadway stopping building streets african century section running parking housing walking avenue routes blocks subway trains though around campus public claude along lines buses stops crime still broad urban line runs stop walk ave bus art st th rd nd av ne dc\n",
      "Topic #2:\n",
      "temperatures reservations backcountry campgrounds temperature conditions elevations campground formations available elevation visitors entrance visitor species camping weather average allowed climate permits animals degrees located canyons usually lodging summer within permit trails months inches ranger common season areas found years winds trees highs often feet year rain mile must days per\n",
      "Topic #3:\n",
      "_massachusetts independent interstate connection wikipedia townships extension turnpike shopping cemetery provides connects minutes becomes traffic railway running borders factory travel rotary routes school listed border season houses motels route along towns small amish hours road pond runs many goes hour away bike next also toll elm via get rd rt\n",
      "Topic #4:\n",
      "opportunities approximately intersection interstate travelers wikipedia grassland services highways interest aircraft visitors hospital wineries highway located lodging largest edwards tasting several options project driving mining hiking nearby offers around remote miners along drive small roses force reach ndash towns space grown road base stop oil gas via hwy one ca\n",
      "Topic #5:\n",
      "restaurant sandwiches atmosphere breakfast delicious selection friendly specials located italian cuisine mexican chinese seafood service offers family coffee school dinner serves dining prices casual pizza lunch grill store cream diner local sushi small food menu cafe good shop best also pike deli thai inn pub ave ice st rd nj\n",
      "Topic #6:\n",
      "established businesses telephone indicated landline omitting requires original february numbers signage consist display leading alcohol overlay package complex parkway nearest seating number dialed digits second entire barren served allows digit seven local sales still codes drink moist voted code call dial plus onto seat many club golf wet ky rd\n",
      "Topic #7:\n",
      "information directions breakfast community wikipedia beautiful hospital pleasure walkable chamber located website welcome content general address antique kitchen avenue minute things drive phone store index visit email check shops farms spend docks hours http many info golf www com org inn ave fax see net bed pa ct nj go\n",
      "Topic #8:\n",
      "transportation passengers interstate terminals concourse available laguardia terminal airlines airports security domestic services stations connects service flights transit shuttle parking minutes located closest airways rental amtrak trains system routes direct livery major train stops offer buses fares lines line rail taxi cars stop runs free ride hour bus car via\n",
      "Topic #9:\n",
      "encompassing northwestern attractions communities spectacular waterfalls associated everything monuments primarily populated counties wineries suburban features railroad includes movement largest explore upstate nowhere thruway hemlock founded famous suburb within mdash small known ndash major civil along areas marta style rides urban wines based vine well part ride pop ll pa st\n",
      "Topic #10:\n",
      "information timberline available breakfast admission boardwalk thursdays saturday thursday children pastries building minutes parking visitor contact tuesday library sundays tickets monday sunday school dinner adults closed hours daily drive rooms night music phone april open road free call noon shop room hour mon sat fri pm sa su pa th\n",
      "Topic #11:\n",
      "incorporated destinations continental destination population breakfast newspaper wikipedia heritage visitors vacation minutes private nearest driving border canada larger people nearby across fiesta crafts closed hours rooms drive small motel local along civil hour coal take tour want away part held inn hwy usa us st wv rd nc sr mi\n",
      "Topic #12:\n",
      "destination attractions lighthouse activities beautiful boardwalk coastline watching vacation aquarium visitors kayaking swimming dramatic beaches fishing popular located seafood tourist surfing courses resorts cannery course marine summer offers beauty hearst famous along enjoy drive known whale shops small large waves seals homes golf many spot also boat mile surf club\n",
      "Topic #13:\n",
      "approximately interstate directions wickenden continue straight entrance settlers parking freeway parkway towards follow avenue toward coming access minute right drive signs along reach merge first exit take road turn onto left walk ride lane mile blvd bart ramp next past get ave one bus see car go sr mt ri\n",
      "Topic #14:\n",
      "neighborhoods neighborhood restaurants residential attractions population including boutiques nightlife shopping numerous located several variety largest options upscale streets popular include centers stores hotels campus retail number dining nearby within places shops along large major chain known found plaza local malls urban areas many bars also well blvd food art one\n",
      "Topic #15:\n",
      "appropriate accessible coastline shellfish sightings developed rewarding organized overnight creatures deciduous estuaries actively kayaking rockfish anything question kayakers explore flyways birders removed society penrose updates paddler popular forests common otters eagles herons launch travel nearby birds areas seals sites kayak lions whale offer thick crabs maps orca boat grey seen\n",
      "Topic #16:\n",
      "incorporated established population settlement originally industrial community residents buildings wikipedia railroad settlers industry building economic century largest located founded company settled english british became school people native called first built today years known named still civil small major began later large part many seat name also well made one th\n",
      "Topic #17:\n",
      "entertainment activities galleries september festivals fireworks festival visitors saturday concerts wineries weekend october theatre artists gallery largest antique vendors outdoor annual parade events crafts august summer campus music local every event hosts shops first enjoy arts held year show july live jazz june free film days fest also tour art\n",
      "Topic #18:\n",
      "accommodation opportunities snowmobiling snowboarding activities timberline snowboard equipment vineyards elevation including climbing rentals resorts outdoor rafting terrain several popular skiing sports rental summer hiking mining biking season trails slopes offers grapes skiers lifts offer towns drive trips lift many base hike also golf rent skis ski tie top ice mt\n",
      "Topic #19:\n",
      "opportunities recreational campground playground activities volleyball basketball available campsites horseback wikipedia primitive reservoir horseshoe swimming electric cottages canoeing fishing camping hunting boating toilets showers located outdoor trails hiking picnic biking courts nature cabins tables riding tennis skiing sites canoe trout flush court boat mile road acre open pool golf one\n"
     ]
    }
   ],
   "source": [
    "vector_features = TFIDFvect.get_feature_names()\n",
    "\n",
    "print_top_words(nmf, vector_features, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPIC: # 0\n",
      "Walt Disney World\n",
      "Saint Thomas\n",
      "New Orleans\n",
      "Great Falls (Montana)\n",
      "Walt Disney World/Magic Kingdom\n",
      "Somers (Connecticut)\n",
      "Santa Fe (New Mexico)\n",
      "Baltimore/Inner Harbor\n",
      "Blowing Rock\n",
      "Rochester (New York)\n",
      "TOPIC: # 1\n",
      "Manhattan/Upper West Side\n",
      "Manhattan/Upper East Side\n",
      "Manhattan/Chelsea\n",
      "Manhattan/Midtown East\n",
      "Washington, D.C./Shaw\n",
      "Manhattan/Theater District\n",
      "Manhattan/Gramercy Flatiron\n",
      "Manhattan/Harlem and Upper Manhattan\n",
      "Manhattan/East Village\n",
      "Minneapolis/Southeast\n",
      "TOPIC: # 2\n",
      "Great Smoky Mountains National Park\n",
      "Rocky Mountain National Park\n",
      "Arches National Park\n",
      "Mount Rainier National Park\n",
      "White Sands National Monument\n",
      "Chiricahua National Monument\n",
      "Yosemite National Park\n",
      "Timpanogos Cave National Monument\n",
      "Sequoia and Kings Canyon National Parks\n",
      "Yellowstone National Park\n",
      "TOPIC: # 3\n",
      "Bangor (Pennsylvania)\n",
      "Nazareth (Pennsylvania)\n",
      "Seekonk\n",
      "Eastham\n",
      "Brewster (Massachusetts)\n",
      "Ashland (Ohio)\n",
      "Sandwich (Massachusetts)\n",
      "Sturbridge\n",
      "Hackettstown\n",
      "Kapolei\n",
      "TOPIC: # 4\n",
      "Tuolumne County\n",
      "Albia\n",
      "Mayfield (Utah)\n",
      "Eminence\n",
      "Moorhead\n",
      "Limestone (Illinois)\n",
      "Swansea (Massachusetts)\n",
      "Bakersfield\n",
      "Windsor (California)\n",
      "Quincy (California)\n",
      "TOPIC: # 5\n",
      "Windsor (Connecticut)\n",
      "Ridgewood\n",
      "Milton (Massachusetts)\n",
      "Elizabeth City\n",
      "Quakertown\n",
      "Sharon (Massachusetts)\n",
      "Westwood (New Jersey)\n",
      "Delaware (Ohio)\n",
      "New Milford\n",
      "Lewes (Delaware)\n",
      "TOPIC: # 6\n",
      "Henderson (Kentucky)\n",
      "Campbellsville (Kentucky)\n",
      "Brownsville (Kentucky)\n",
      "Hodgenville\n",
      "Grand Rivers\n",
      "Jasper (Indiana)\n",
      "Calvert City\n",
      "Elizabethtown (Kentucky)\n",
      "Russellville (Kentucky)\n",
      "Gilbertsville\n",
      "TOPIC: # 7\n",
      "Mercer County (New Jersey)\n",
      "Huron (Ohio)\n",
      "Vermilion (Ohio)\n",
      "Winter Park (Florida)\n",
      "Clarks Summit\n",
      "Barkhamsted\n",
      "Pelham (New York)\n",
      "Charlestown (Rhode Island)\n",
      "Haddonfield\n",
      "Burney\n",
      "TOPIC: # 8\n",
      "John F. Kennedy International Airport\n",
      "Newark Liberty International Airport\n",
      "Seattle-Tacoma International Airport\n",
      "San Francisco International Airport\n",
      "O'Hare International Airport\n",
      "Los Angeles International Airport\n",
      "Detroit Metropolitan Wayne County Airport\n",
      "Miami International Airport\n",
      "Orlando International Airport\n",
      "Hartsfield–Jackson Atlanta International Airport\n",
      "TOPIC: # 9\n",
      "United States National Parks\n",
      "Northtowns\n",
      "Northeastern Utah\n",
      "Western Finger Lakes\n",
      "Finger Lakes\n",
      "Early United States history\n",
      "Canyon Country\n",
      "Eastern Finger Lakes\n",
      "Disneyland\n",
      "Utah's Dixie\n",
      "TOPIC: # 10\n",
      "East Bridgewater\n",
      "Lewisburg (West Virginia)\n",
      "Ledyard (Connecticut)\n",
      "Stoughton (Massachusetts)\n",
      "Dexter (Michigan)\n",
      "Kingston (Rhode Island)\n",
      "Chelsea (Michigan)\n",
      "Danvers\n",
      "Shrewsbury (Pennsylvania)\n",
      "Valdosta\n",
      "TOPIC: # 11\n",
      "Traverse City\n",
      "Weston (West Virginia)\n",
      "Fayetteville (West Virginia)\n",
      "Bluemont\n",
      "Rochester (Indiana)\n",
      "Point Roberts\n",
      "Ithaca (Michigan)\n",
      "Minot\n",
      "Elkins\n",
      "Gilbertsville\n",
      "TOPIC: # 12\n",
      "Monterey Bay\n",
      "Central Coast (California)\n",
      "Monterey County\n",
      "Santa Cruz County\n",
      "Jersey Shore\n",
      "Pacific Grove\n",
      "Santa Cruz (California)\n",
      "Carmel (California)\n",
      "Playa del Rey\n",
      "North Carolina Coastal Plain\n",
      "TOPIC: # 13\n",
      "Murfreesboro\n",
      "Detroit/Downtown\n",
      "Detroit/Midtown-New Center\n",
      "Georgetown (Colorado)\n",
      "Wilmington (Massachusetts)\n",
      "Macon (Georgia)\n",
      "Scituate (Massachusetts)\n",
      "Providence/College Hill\n",
      "Evergreen Park (Illinois)\n",
      "Shickshinny\n",
      "TOPIC: # 14\n",
      "Los Angeles/West\n",
      "Dallas\n",
      "Westside (Los Angeles County)\n",
      "Davis (California)\n",
      "Pittsburgh/South Side\n",
      "Mountain View (California)\n",
      "Portland (Maine)\n",
      "Pittsburgh/Strip District-Lawrenceville\n",
      "Culver City\n",
      "Fort Lee\n",
      "TOPIC: # 15\n",
      "Purdy (Washington)\n",
      "Lakebay\n",
      "Hansville (Washington)\n",
      "Manchester (Washington)\n",
      "Poulsbo\n",
      "Home (Washington)\n",
      "Kingston (Washington)\n",
      "Southworth (Washington)\n",
      "Key Center\n",
      "Kitsap Peninsula\n",
      "TOPIC: # 16\n",
      "Industrialization of the United States\n",
      "Merrimack\n",
      "Old West\n",
      "Ellsworth (Maine)\n",
      "Peabody\n",
      "Mid-Hudson and Catskills\n",
      "Fort Myers\n",
      "Buffalo\n",
      "Forney\n",
      "South (United States of America)\n",
      "TOPIC: # 17\n",
      "Nine-County Region\n",
      "Asbury Park\n",
      "Indiana\n",
      "Flint\n",
      "Gresham\n",
      "Baldwin City\n",
      "Rhode Island\n",
      "Denver\n",
      "Natchitoches\n",
      "Hotchkiss\n",
      "TOPIC: # 18\n",
      "Steamboat Springs\n",
      "Breckenridge (Colorado)\n",
      "Keystone (Colorado)\n",
      "Vail\n",
      "Alta (Utah)\n",
      "Beaver Creek\n",
      "Mammoth Lakes\n",
      "Government Camp\n",
      "Ellicottville\n",
      "Aspen\n",
      "TOPIC: # 19\n",
      "Northwest Ohio\n",
      "Ross County\n",
      "Ashland County (Ohio)\n",
      "Athens (Ohio)\n",
      "Lake County (Florida)\n",
      "Butler County (Ohio)\n",
      "Jefferson County (Ohio)\n",
      "Portage County\n",
      "Monett\n",
      "Chillicothe (Ohio)\n"
     ]
    }
   ],
   "source": [
    "for topic in range(W.shape[1]):\n",
    "    #max_t = np.argmax(W[:,topic])\n",
    "    print \"TOPIC: #\",topic\n",
    "    #print features[max_t][0:150]\n",
    "    \n",
    "    for t in range(10):\n",
    "        n = int(-1-t)\n",
    "        max_2t = W[:,topic].argsort()[n]\n",
    "        print list(pages2['Name'])[max_2t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "pages2['tb'] = pages2['text'].map(lambda x: TextBlob(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "pages2['polarity'] = pages2['tb'].map(lambda x: x.sentiment[0])\n",
    "pages2['subjectivity'] = pages2['tb'].map(lambda x: x.sentiment[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-9a833fa3b444>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpages2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpages2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'lat\\=([0-9.]*)(?=\\&)'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   2014\u001b[0m                                      index=self.index).__finalize__(self)\n\u001b[1;32m   2015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2016\u001b[0;31m             \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2017\u001b[0m             return self._constructor(mapped,\n\u001b[1;32m   2018\u001b[0m                                      index=self.index).__finalize__(self)\n",
      "\u001b[0;32mpandas/src/inference.pyx\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas/lib.c:58435)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-9a833fa3b444>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpages2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpages2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'lat\\=([0-9.]*)(?=\\&)'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "pages2['lat'] = pages2['loc'].map(lambda x: re.findall(r'lat\\=([0-9.]*)(?=\\&)',x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "pages2['lon'] = pages2['loc'].map(lambda x: re.findall(r'lon\\=([\\-0-9.]*)(?=\\&)',x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=5)\n",
    "cluster_labels = clusterer.fit_predict(x_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({-1: 2288,\n",
       "         0: 13,\n",
       "         1: 11,\n",
       "         2: 9,\n",
       "         3: 13,\n",
       "         4: 9,\n",
       "         5: 26,\n",
       "         6: 27,\n",
       "         7: 32,\n",
       "         8: 21,\n",
       "         9: 6,\n",
       "         10: 10,\n",
       "         11: 9,\n",
       "         12: 33,\n",
       "         13: 9})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pages3 = pages2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Name</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>loc</th>\n",
       "      <th>regex_text</th>\n",
       "      <th>len</th>\n",
       "      <th>tb</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>92</td>\n",
       "      <td>Alta (Utah)</td>\n",
       "      <td>\\nAlta is a small town at the head of Little C...</td>\n",
       "      <td>page</td>\n",
       "      <td>//tools.wmflabs.org/wikivoyage/w/poimap2.php?l...</td>\n",
       "      <td>\\nAlta is a small town at the head of Little C...</td>\n",
       "      <td>2739</td>\n",
       "      <td>(\\n, A, l, t, a,  , i, s,  , a,  , s, m, a, l,...</td>\n",
       "      <td>0.110258</td>\n",
       "      <td>0.431247</td>\n",
       "      <td>-111.637222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>429</td>\n",
       "      <td>Beaver Creek</td>\n",
       "      <td>\\nBeaver Creek is a ski resort in Colorado.\\n\\...</td>\n",
       "      <td>page</td>\n",
       "      <td>//tools.wmflabs.org/wikivoyage/w/poimap2.php?l...</td>\n",
       "      <td>\\nBeaver Creek is a ski resort in Colorado.\\n\\...</td>\n",
       "      <td>1921</td>\n",
       "      <td>(\\n, B, e, a, v, e, r,  , C, r, e, e, k,  , i,...</td>\n",
       "      <td>0.191499</td>\n",
       "      <td>0.510305</td>\n",
       "      <td>-106.521667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>695</td>\n",
       "      <td>Breckenridge (Colorado)</td>\n",
       "      <td>\\n\\nBreckenridge is a ski resort and town at t...</td>\n",
       "      <td>page</td>\n",
       "      <td>//tools.wmflabs.org/wikivoyage/w/poimap2.php?l...</td>\n",
       "      <td>\\n\\nBreckenridge is a ski resort and town at t...</td>\n",
       "      <td>1990</td>\n",
       "      <td>(\\n, \\n, B, r, e, c, k, e, n, r, i, d, g, e,  ...</td>\n",
       "      <td>0.145347</td>\n",
       "      <td>0.376436</td>\n",
       "      <td>-106.03833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>3039</td>\n",
       "      <td>Government Camp</td>\n",
       "      <td>\\nGovernment Camp is a city in Oregon.\\n\\n==Un...</td>\n",
       "      <td>page</td>\n",
       "      <td>//tools.wmflabs.org/wikivoyage/w/poimap2.php?l...</td>\n",
       "      <td>\\nGovernment Camp is a city in Oregon.\\n\\n\\nGo...</td>\n",
       "      <td>2126</td>\n",
       "      <td>(\\n, G, o, v, e, r, n, m, e, n, t,  , C, a, m,...</td>\n",
       "      <td>0.147991</td>\n",
       "      <td>0.288876</td>\n",
       "      <td>-121.756667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>3712</td>\n",
       "      <td>Keystone (Colorado)</td>\n",
       "      <td>\\nKeystone is a ski resort in Colorado.\\n\\n==G...</td>\n",
       "      <td>page</td>\n",
       "      <td>//tools.wmflabs.org/wikivoyage/w/poimap2.php?l...</td>\n",
       "      <td>\\nKeystone is a ski resort in Colorado.\\n\\n\\nW...</td>\n",
       "      <td>2134</td>\n",
       "      <td>(\\n, K, e, y, s, t, o, n, e,  , i, s,  , a,  ,...</td>\n",
       "      <td>0.249995</td>\n",
       "      <td>0.484613</td>\n",
       "      <td>-105.948056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>3831</td>\n",
       "      <td>Lake Tahoe</td>\n",
       "      <td>\\n\\n\\nLake Tahoe is a popular vacation and rec...</td>\n",
       "      <td>page</td>\n",
       "      <td>//tools.wmflabs.org/wikivoyage/w/poimap2.php?l...</td>\n",
       "      <td>\\n\\n\\nLake Tahoe is a popular vacation and rec...</td>\n",
       "      <td>8470</td>\n",
       "      <td>(\\n, \\n, \\n, L, a, k, e,  , T, a, h, o, e,  , ...</td>\n",
       "      <td>0.149287</td>\n",
       "      <td>0.444646</td>\n",
       "      <td>-120.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>4163</td>\n",
       "      <td>Mammoth Lakes</td>\n",
       "      <td>\\n\\nMammoth Lakes is a resort city next to Mam...</td>\n",
       "      <td>page</td>\n",
       "      <td>//tools.wmflabs.org/wikivoyage/w/poimap2.php?l...</td>\n",
       "      <td>\\n\\nMammoth Lakes is a resort city next to Mam...</td>\n",
       "      <td>1986</td>\n",
       "      <td>(\\n, \\n, M, a, m, m, o, t, h,  , L, a, k, e, s...</td>\n",
       "      <td>0.163889</td>\n",
       "      <td>0.463593</td>\n",
       "      <td>-118.971944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>6333</td>\n",
       "      <td>Steamboat Springs</td>\n",
       "      <td>\\nSteamboat Springs is a ski resort in the sta...</td>\n",
       "      <td>page</td>\n",
       "      <td>//tools.wmflabs.org/wikivoyage/w/poimap2.php?l...</td>\n",
       "      <td>\\nSteamboat Springs is a ski resort in the sta...</td>\n",
       "      <td>4705</td>\n",
       "      <td>(\\n, S, t, e, a, m, b, o, a, t,  , S, p, r, i,...</td>\n",
       "      <td>0.128398</td>\n",
       "      <td>0.432170</td>\n",
       "      <td>-106.826667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327</th>\n",
       "      <td>6677</td>\n",
       "      <td>Vail</td>\n",
       "      <td>\\n\\n\\nVail is a U.S. ski resort town set in th...</td>\n",
       "      <td>page</td>\n",
       "      <td>//tools.wmflabs.org/wikivoyage/w/poimap2.php?l...</td>\n",
       "      <td>\\n\\n\\nVail is a U.S. ski resort town set in th...</td>\n",
       "      <td>9618</td>\n",
       "      <td>(\\n, \\n, \\n, V, a, i, l,  , i, s,  , a,  , U, ...</td>\n",
       "      <td>0.208165</td>\n",
       "      <td>0.490211</td>\n",
       "      <td>-106.363056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                     Name  \\\n",
       "29       92              Alta (Utah)   \n",
       "158     429             Beaver Creek   \n",
       "269     695  Breckenridge (Colorado)   \n",
       "876    3039          Government Camp   \n",
       "1140   3712      Keystone (Colorado)   \n",
       "1178   3831               Lake Tahoe   \n",
       "1302   4163            Mammoth Lakes   \n",
       "2207   6333        Steamboat Springs   \n",
       "2327   6677                     Vail   \n",
       "\n",
       "                                                   text  type  \\\n",
       "29    \\nAlta is a small town at the head of Little C...  page   \n",
       "158   \\nBeaver Creek is a ski resort in Colorado.\\n\\...  page   \n",
       "269   \\n\\nBreckenridge is a ski resort and town at t...  page   \n",
       "876   \\nGovernment Camp is a city in Oregon.\\n\\n==Un...  page   \n",
       "1140  \\nKeystone is a ski resort in Colorado.\\n\\n==G...  page   \n",
       "1178  \\n\\n\\nLake Tahoe is a popular vacation and rec...  page   \n",
       "1302  \\n\\nMammoth Lakes is a resort city next to Mam...  page   \n",
       "2207  \\nSteamboat Springs is a ski resort in the sta...  page   \n",
       "2327  \\n\\n\\nVail is a U.S. ski resort town set in th...  page   \n",
       "\n",
       "                                                    loc  \\\n",
       "29    //tools.wmflabs.org/wikivoyage/w/poimap2.php?l...   \n",
       "158   //tools.wmflabs.org/wikivoyage/w/poimap2.php?l...   \n",
       "269   //tools.wmflabs.org/wikivoyage/w/poimap2.php?l...   \n",
       "876   //tools.wmflabs.org/wikivoyage/w/poimap2.php?l...   \n",
       "1140  //tools.wmflabs.org/wikivoyage/w/poimap2.php?l...   \n",
       "1178  //tools.wmflabs.org/wikivoyage/w/poimap2.php?l...   \n",
       "1302  //tools.wmflabs.org/wikivoyage/w/poimap2.php?l...   \n",
       "2207  //tools.wmflabs.org/wikivoyage/w/poimap2.php?l...   \n",
       "2327  //tools.wmflabs.org/wikivoyage/w/poimap2.php?l...   \n",
       "\n",
       "                                             regex_text   len  \\\n",
       "29    \\nAlta is a small town at the head of Little C...  2739   \n",
       "158   \\nBeaver Creek is a ski resort in Colorado.\\n\\...  1921   \n",
       "269   \\n\\nBreckenridge is a ski resort and town at t...  1990   \n",
       "876   \\nGovernment Camp is a city in Oregon.\\n\\n\\nGo...  2126   \n",
       "1140  \\nKeystone is a ski resort in Colorado.\\n\\n\\nW...  2134   \n",
       "1178  \\n\\n\\nLake Tahoe is a popular vacation and rec...  8470   \n",
       "1302  \\n\\nMammoth Lakes is a resort city next to Mam...  1986   \n",
       "2207  \\nSteamboat Springs is a ski resort in the sta...  4705   \n",
       "2327  \\n\\n\\nVail is a U.S. ski resort town set in th...  9618   \n",
       "\n",
       "                                                     tb  polarity  \\\n",
       "29    (\\n, A, l, t, a,  , i, s,  , a,  , s, m, a, l,...  0.110258   \n",
       "158   (\\n, B, e, a, v, e, r,  , C, r, e, e, k,  , i,...  0.191499   \n",
       "269   (\\n, \\n, B, r, e, c, k, e, n, r, i, d, g, e,  ...  0.145347   \n",
       "876   (\\n, G, o, v, e, r, n, m, e, n, t,  , C, a, m,...  0.147991   \n",
       "1140  (\\n, K, e, y, s, t, o, n, e,  , i, s,  , a,  ,...  0.249995   \n",
       "1178  (\\n, \\n, \\n, L, a, k, e,  , T, a, h, o, e,  , ...  0.149287   \n",
       "1302  (\\n, \\n, M, a, m, m, o, t, h,  , L, a, k, e, s...  0.163889   \n",
       "2207  (\\n, S, t, e, a, m, b, o, a, t,  , S, p, r, i,...  0.128398   \n",
       "2327  (\\n, \\n, \\n, V, a, i, l,  , i, s,  , a,  , U, ...  0.208165   \n",
       "\n",
       "      subjectivity          lon  \n",
       "29        0.431247  -111.637222  \n",
       "158       0.510305  -106.521667  \n",
       "269       0.376436   -106.03833  \n",
       "876       0.288876  -121.756667  \n",
       "1140      0.484613  -105.948056  \n",
       "1178      0.444646  -120.041667  \n",
       "1302      0.463593  -118.971944  \n",
       "2207      0.432170  -106.826667  \n",
       "2327      0.490211  -106.363056  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages3.ix[np.where(cluster_labels == 13)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words=StopWords)\n",
    "x_features = vect.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=10)\n",
    "cluster_labels = clusterer.fit_predict(x_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({-1: 1870, 0: 635, 1: 11})"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(cluster_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Consider breaking text into sections (e.g. DO, EAT, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Remove get in/ get around sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Try POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Consider NER for names of restaurants, hotels, etc. so "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Consider removing airports\n",
    "## Combine city sections into one\n",
    "## Remove National parks and history pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Add European Data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
